{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "456c29cc",
   "metadata": {},
   "source": [
    "## Velocity-Oriented Analytics (Deviation from True Streaming)\n",
    "\n",
    "This notebook demonstrates velocity-oriented data processing through a controlled\n",
    "micro-batch simulation rather than true real-time streaming. While Apache Spark\n",
    "Structured Streaming was initially considered, platform-specific limitations led to\n",
    "the adoption of a bounded micro-batch approach.\n",
    "\n",
    "By processing the dataset incrementally in fixed-size batches and recomputing analytics\n",
    "over time, this approach captures the core principles of data velocity, including\n",
    "incremental computation, temporal ordering, and evolving insights, while ensuring\n",
    "reproducibility and stable execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb9f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-SQR20TT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ProstateCancerVelocitySimulation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x206695d7750>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ProstateCancerVelocitySimulation\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4524d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Patient_ID: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Family_History: string (nullable = true)\n",
      " |-- Race_African_Ancestry: string (nullable = true)\n",
      " |-- PSA_Level: double (nullable = true)\n",
      " |-- DRE_Result: string (nullable = true)\n",
      " |-- Biopsy_Result: string (nullable = true)\n",
      " |-- Difficulty_Urinating: string (nullable = true)\n",
      " |-- Weak_Urine_Flow: string (nullable = true)\n",
      " |-- Blood_in_Urine: string (nullable = true)\n",
      " |-- Pelvic_Pain: string (nullable = true)\n",
      " |-- Back_Pain: string (nullable = true)\n",
      " |-- Erectile_Dysfunction: string (nullable = true)\n",
      " |-- Cancer_Stage: string (nullable = true)\n",
      " |-- Treatment_Recommended: string (nullable = true)\n",
      " |-- Survival_5_Years: string (nullable = true)\n",
      " |-- Exercise_Regularly: string (nullable = true)\n",
      " |-- Healthy_Diet: string (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- Smoking_History: string (nullable = true)\n",
      " |-- Alcohol_Consumption: string (nullable = true)\n",
      " |-- Hypertension: string (nullable = true)\n",
      " |-- Diabetes: string (nullable = true)\n",
      " |-- Cholesterol_Level: string (nullable = true)\n",
      " |-- Screening_Age: integer (nullable = true)\n",
      " |-- Follow_Up_Required: string (nullable = true)\n",
      " |-- Prostate_Volume: double (nullable = true)\n",
      " |-- Genetic_Risk_Factors: string (nullable = true)\n",
      " |-- Previous_Cancer_History: string (nullable = true)\n",
      " |-- Early_Detection: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"prostate_cancer_prediction.csv\")\n",
    "\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a3fcb",
   "metadata": {},
   "source": [
    "#### Adding synthetic time dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4709d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+--------------+---------------------+---------+----------+-------------+--------------------+---------------+--------------+-----------+---------+--------------------+------------+---------------------+----------------+------------------+------------+----+---------------+-------------------+------------+--------+-----------------+-------------+------------------+---------------+--------------------+-----------------------+---------------+----------+\n",
      "|Patient_ID|Age|Family_History|Race_African_Ancestry|PSA_Level|DRE_Result|Biopsy_Result|Difficulty_Urinating|Weak_Urine_Flow|Blood_in_Urine|Pelvic_Pain|Back_Pain|Erectile_Dysfunction|Cancer_Stage|Treatment_Recommended|Survival_5_Years|Exercise_Regularly|Healthy_Diet| BMI|Smoking_History|Alcohol_Consumption|Hypertension|Diabetes|Cholesterol_Level|Screening_Age|Follow_Up_Required|Prostate_Volume|Genetic_Risk_Factors|Previous_Cancer_History|Early_Detection|arrival_id|\n",
      "+----------+---+--------------+---------------------+---------+----------+-------------+--------------------+---------------+--------------+-----------+---------+--------------------+------------+---------------------+----------------+------------------+------------+----+---------------+-------------------+------------+--------+-----------------+-------------+------------------+---------------+--------------------+-----------------------+---------------+----------+\n",
      "|         1| 78|            No|                  Yes|     5.07|    Normal|       Benign|                  No|             No|            No|         No|       No|                  No|   Localized|  Active Surveillance|             Yes|                No|         Yes|22.3|            Yes|           Moderate|          No|      No|           Normal|           45|                No|           46.0|                  No|                     No|            Yes|         0|\n",
      "|         2| 68|            No|                  Yes|    10.24|    Normal|       Benign|                 Yes|             No|            No|        Yes|       No|                  No|   Localized|  Active Surveillance|             Yes|               Yes|          No|20.4|             No|                Low|          No|      No|             High|           65|                No|           78.2|                  No|                     No|            Yes|         1|\n",
      "|         3| 54|            No|                   No|    13.79|    Normal|       Benign|                  No|             No|            No|        Yes|       No|                  No|  Metastatic|            Radiation|             Yes|                No|         Yes|20.5|            Yes|                Low|          No|      No|           Normal|           61|                No|           21.1|                  No|                     No|            Yes|         2|\n",
      "|         4| 82|            No|                   No|     8.03|  Abnormal|       Benign|                  No|             No|            No|         No|       No|                  No|   Localized|        Immunotherapy|             Yes|               Yes|         Yes|28.4|             No|                Low|          No|      No|           Normal|           47|               Yes|           79.9|                  No|                    Yes|            Yes|         3|\n",
      "|         5| 47|           Yes|                   No|     1.89|    Normal|    Malignant|                 Yes|            Yes|            No|         No|       No|                  No|    Advanced|  Active Surveillance|             Yes|               Yes|         Yes|30.1|             No|           Moderate|         Yes|      No|           Normal|           72|                No|           32.0|                  No|                     No|            Yes|         4|\n",
      "+----------+---+--------------+---------------------+---------+----------+-------------+--------------------+---------------+--------------+-----------+---------+--------------------+------------+---------------------+----------------+------------------+------------+----+---------------+-------------------+------------+--------+-----------------+-------------+------------------+---------------+--------------------+-----------------------+---------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df_with_time = df.withColumn(\n",
    "    \"arrival_id\",\n",
    "    monotonically_increasing_id()\n",
    ")\n",
    "\n",
    "df_with_time.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2cf3c",
   "metadata": {},
   "source": [
    "#### Define Micro-Batch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675de10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 27945\n",
      "Micro-batch size: 100\n",
      "Maximum batches to process: 5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "MAX_BATCHES = 5   # limits runtime intentionally\n",
    "\n",
    "TOTAL_ROWS = df_with_time.count()\n",
    "\n",
    "print(f\"Total records: {TOTAL_ROWS}\")\n",
    "print(f\"Micro-batch size: {BATCH_SIZE}\")\n",
    "print(f\"Maximum batches to process: {MAX_BATCHES}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f70105",
   "metadata": {},
   "source": [
    "#### Micro-Batch Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07b1de6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Micro-Batch 1 ===\n",
      "Time: 17:46:59\n",
      "+------------+-----------------+\n",
      "|Cancer_Stage|          avg_psa|\n",
      "+------------+-----------------+\n",
      "|   Localized| 8.15164383561644|\n",
      "|    Advanced|6.461052631578947|\n",
      "|  Metastatic|         10.31625|\n",
      "+------------+-----------------+\n",
      "\n",
      "\n",
      "=== Processing Micro-Batch 2 ===\n",
      "Time: 17:47:01\n",
      "+------------+-----------------+\n",
      "|Cancer_Stage|          avg_psa|\n",
      "+------------+-----------------+\n",
      "|   Localized|7.918311688311684|\n",
      "|    Advanced|6.845000000000001|\n",
      "|  Metastatic|7.788571428571428|\n",
      "+------------+-----------------+\n",
      "\n",
      "\n",
      "=== Processing Micro-Batch 3 ===\n",
      "Time: 17:47:03\n",
      "+------------+-----------------+\n",
      "|Cancer_Stage|          avg_psa|\n",
      "+------------+-----------------+\n",
      "|   Localized| 8.91051724137931|\n",
      "|    Advanced|6.239142857142856|\n",
      "|  Metastatic|7.195714285714287|\n",
      "+------------+-----------------+\n",
      "\n",
      "\n",
      "=== Processing Micro-Batch 4 ===\n",
      "Time: 17:47:05\n",
      "+------------+------------------+\n",
      "|Cancer_Stage|           avg_psa|\n",
      "+------------+------------------+\n",
      "|   Localized| 7.528309859154932|\n",
      "|    Advanced|7.9592307692307696|\n",
      "|  Metastatic| 7.993124999999999|\n",
      "+------------+------------------+\n",
      "\n",
      "\n",
      "=== Processing Micro-Batch 5 ===\n",
      "Time: 17:47:08\n",
      "+------------+------------------+\n",
      "|Cancer_Stage|           avg_psa|\n",
      "+------------+------------------+\n",
      "|   Localized|  8.22764705882353|\n",
      "|    Advanced|6.7551999999999985|\n",
      "|  Metastatic| 9.397142857142857|\n",
      "+------------+------------------+\n",
      "\n",
      "\n",
      "Velocity simulation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "import time\n",
    "\n",
    "current_offset = 0\n",
    "batch_number = 1\n",
    "\n",
    "while current_offset < TOTAL_ROWS and batch_number <= MAX_BATCHES:\n",
    "    print(f\"\\n=== Processing Micro-Batch {batch_number} ===\")\n",
    "    print(f\"Time: {time.strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    micro_batch = (\n",
    "        df_with_time\n",
    "        .filter(\n",
    "            (df_with_time.arrival_id >= current_offset) &\n",
    "            (df_with_time.arrival_id < current_offset + BATCH_SIZE)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result = micro_batch.groupBy(\"Cancer_Stage\").agg(\n",
    "        avg(\"PSA_Level\").alias(\"avg_psa\")\n",
    "    )\n",
    "    \n",
    "    result.show()\n",
    "    \n",
    "    current_offset += BATCH_SIZE\n",
    "    batch_number += 1\n",
    "    \n",
    "    # Simulate delay between arrivals\n",
    "    time.sleep(2)\n",
    "\n",
    "print(\"\\nVelocity simulation completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43f1cb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The velocity simulation demonstrates how analytical results can be updated as new data\n",
    "arrives incrementally. By recomputing metrics over successive micro-batches, this\n",
    "notebook illustrates the impact of data velocity on analytics without requiring\n",
    "continuous streaming infrastructure.\n",
    "\n",
    "This approach complements the batch analytics by showing how population-level insights\n",
    "can be observed dynamically over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897249c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
